"SSD хорошо работает при RANDOM ACCESS на read операции, но при write происходит copy-on-write...
если минимальный размер записи 2Mb, а надо записать 4кб..то придется считать 2Mb, сделать копию + 2Mb, изменить 4кб и положить обратно..
Витоге при 400 таких IOps-ов читать придется 800Mb/s
для ramdisk-a минимальный блок для  DDR -  128б..в тестах минимум 4кб используют."
меряем нагрузку в IOPs-ах в больших системах kIOPs-ах
IOPs бывают разные и дают разную нагрузку (пишет случайными блоками, или читает последовательными, маленькие, большие, подряд, вразнобой..будут читать из кэша либо с самого медленного места на диске...)
"для тестов нужно определить
1.best case - попад. в кэш, последовательные оп-ции
2. worst case - нужно достичь результата - мимо кэша (напр. кэш 64Mb, а область тестирования 2Гб), читать напрямуя в самой трудносдоступной области диска (внутр. ближе к шпинделю)

Могут получится результаты напр. 5kIOPS и 150 IOPS"
размер блока для тэста берут 4к - стандартный размер для OS.
при worst 100IOps c блоком 4к, то с блоком 8к меньше ~ 70-80IOps..
зависимые IOPS-ы - прочитать запись/поменять запись/записать запись обратно
"тэст на зависимость - время обработки нулевое, 1 запрос на чтение и запись по 1мс  -> 500 запросов  за 1cек.
запуск копии приложения получим 1000 IOPs-ов..если меньше  мы достигли предела производительности системы.
Иначе произв. ограничивает  latency  или уровень зависимости IOPs"
"Latency сложна для измерения, проблема что запросы выполняются либо быстро, либо медленно..берется avg времени задержки, либо медиана
плюс у разных систем длина очереди может достигать до несколько тыс. у мощьных (глубина очереди)"
"Latency напрямую влияет на зависимость производительности
пример:
При 5мс максимальное число запросов — 200 шт/с, при 20мс — 50.
При этом если у нас 100 запросов будут обработаны за 1мс, а 9 запросов — за 100мс,
то за секунду мы получим всего 109 IOPS, при медиане в 1мс и avg (среднем) в 10мс."
"На производительность влияет тип приложения..на десктопах апликиции при запуске последовательно считывают инфу и загружают либы,
на web сервере параллельно выполняются запросы на клиента напр. 1мс-10мс..вопрос сколько запросов может одновременно пройти при такой latency"
"trashing - когда забивается очередь...показывается большое кол-во IOPs-ов(больше чем при спокойном состоянии), потому что идет постоянное обслуживание.
latency растет..ждем пока обработают (сравнение с супермаркетами..кассир работает запредельно, клиент недовольный ждет).
поэтому рекомендуют делать тесты ориентируясь на latency 10мс + брать 10 про запас, тип если больше 20мс - понимаем что пойдут лаги..
При такой latency  меряем IOPs-ы."
вобщем при последовательных запросах контролирум только latency...при паралельных запускаем паралельные запросыб при определенной latency, смотрим сколько их
"SAN и NAS по сети с использованием TCP.
в линуксе 12 способов контроля заторов (congestion)
~20 параметров ядра для тюнинга..
тестить хралище нужно с разных хостов. Иначе это будет тестом сети, хранилища и правильности настройки самого сервера."
"ssd - 400mb/s по SATA/300 не даст такой произв.
 SATA-кабель - bottleneck при уже 300мб/с
полка дисков, подключенных по SAS/300x4 (т.е. 4 линии SAS по 300МБ каждая).
Вроде бы много. А если в полке 24 диска? 24*100=2400 МБ/с, а у нас есть всего 1200 (300х4).
тесты на некоторых (серверных!) материнских платах показали, что встроенные SATA-контроллеры
часто бывают подключены через PCIx4, что не даёт максимально возможной скорости всех 6 SATA-разъёмов."

"Обход cache-
 worst case является «трешинг кеша», то есть посыл запросов на запись в таком объёме и так долго, чтобы write cache перестал стправляться и был вынужден писать данные не в комфортном режиме (объединяя смежные области), а скидывать случайные данные, осуществляя random writing
Вердикт — минимум x10 кеш"
"Описание теста


Итого:
1) Мы тестируем worst case — 100% размера диска, который в несколько раз больше предположительного размера кеша на хранилище. Для десктопа это всего лишь «весь диск», для индустриальных хранилищ — LUN или диск виртуальной машины размером от 1Тб и больше. (Хехе, если вы думаете, что 64Гб RAM-кеша это много...).
2) Мы ведём тест блоком в 4кб размером.
3) Мы подбираем такую глубину параллельности операций, чтобы latency оставалось в разумных пределах.

На выходе нас интересуют параметры: число IOPS, latency, глубина очереди. Если тест запускался на нескольких хостах, то показатели суммируются (iops и глубина очереди), а для latency берётся либо avg, либо max от показателей по всем хостам."
"fio


Тут мы переходим к практической части. Есть утилита fio которая позволяет добиться нужного нам результата.

Нормальный режим fio подразумевает использование т.н. job-файла, т.е. конфига, который описывает как именно выглядит тест. Примеры job-файлов приведены ниже, а пока что обсудим принцип работы fio.

fio выполняет операции над указанным файлом/файлами. Вместо файла может быть указано устройство, т.е. мы можем исключить файловую систему из рассмотрения. Существует несколько режимов тестирования. Нас интересует randwrite, randread и randrw. К сожалению, randrw даёт нам зависимые iops'ы (чтение идёт после записи), так что для получения полностью независимого теста нам придётся делать две параллельные задачи — одна на чтение, вторая на запись (randread, randwrite).

И нам придётся сказать fio делать «preallocation». (см выше про трюки производителей). Дальше мы фиксируем размер блока (4к).

Ещё один параметр — метод доступа к диску. Наиболее быстрым является libaio, именно его мы и будем использовать.

Практические рецепты


Установка fio: apt-get install fio (debian/ubntu). Если что, в squeze ещё её нет.
Утилита весьма хитро запрятана, так что «home page» у неё просто нет, только гит-репозиторий. Вот одно из зеркал: freecode.com/projects/fio

При тесте диска запускать её надо от root'а.

тесты на чтение

Запуск: fio read.ini
Содержимое read.ini
[readtest]
blocksize=4k
filename=/dev/sda
rw=randread
direct=1
buffered=0
ioengine=libaio
iodepth=32

Задача подобрать такой iodepth, чтобы avg.latency была меньше 10мс.

Тесты на запись

(внимание! Ошибётесь буквой диска — останетесь без данных)
[writetest]
blocksize=4k
filename=/dev/sdz
rw=randwrite
direct=1
buffered=0
ioengine=libaio
iodepth=32

Гибридные тесты

самая вкусная часть:
(внимание! Ошибётесь буквой диска — останетесь без данных)
[readtest]
blocksize=4k
filename=/dev/sdz
rw=randread
direct=1
buffered=0
ioengine=libaio
iodepth=32
[writetest]
blocksize=4k
filename=/dev/sdz
rw=randwrite
direct=1
buffered=0
ioengine=libaio
iodepth=32


Анализ вывода


Во время теста мы видим что-то вроде такого:
Jobs: 2 (f=2): [rw] [2.8% done] [13312K/11001K /s] [3250/2686 iops] [eta 05m:12s]


В квадратных скобках — цифры IOPS'ов. Но радоваться рано — ведь нас интересует latency.

На выходе (по Ctrl-C, либо по окончании) мы получим примерно вот такое:

^C
fio: terminating on signal 2
read: (groupid=0, jobs=1): err= 0: pid=11048
  read : io=126480KB, bw=14107KB/s, iops=3526, runt=  8966msec
    slat (usec): min=3, max=432, avg= 6.19, stdev= 6.72
    clat (usec): min=387, max=208677, avg=9063.18, stdev=22736.45
    bw (KB/s) : min=10416, max=18176, per=98.74%, avg=13928.29, stdev=2414.65
  cpu          : usr=1.56%, sys=3.17%, ctx=15636, majf=0, minf=57
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=99.9%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued r/w: total=31620/0, short=0/0
     lat (usec): 500=0.07%, 750=0.99%, 1000=2.76%
     lat (msec): 2=16.55%, 4=35.21%, 10=35.47%, 20=3.68%, 50=0.76%
     lat (msec): 100=0.08%, 250=4.43%
write: (groupid=0, jobs=1): err= 0: pid=11050
  write: io=95280KB, bw=10630KB/s, iops=2657, runt=  8963msec
    slat (usec): min=3, max=907, avg= 7.60, stdev=11.68
    clat (usec): min=589, max=162693, avg=12028.23, stdev=25166.31
    bw (KB/s) : min= 6666, max=14304, per=100.47%, avg=10679.50, stdev=2141.46
  cpu          : usr=0.49%, sys=3.57%, ctx=12075, majf=0, minf=25
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=99.9%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued r/w: total=0/23820, short=0/0
     lat (usec): 750=0.03%, 1000=0.37%
     lat (msec): 2=9.04%, 4=24.53%, 10=49.72%, 20=9.56%, 50=0.82%
     lat (msec): 100=0.07%, 250=5.87%


Нас из этого интересует (в минимальном случае) следующее:
read: iops=3526 clat=9063.18 (usec), то есть 9мс.
write: iops=2657 clat=12028.23

Не путайте slat и clat. slat — это время отправки запроса (т.е. производительность дискового стека линукса), а clat — это complete latency, то есть та latency, о которой мы говорили. Легко видеть, что чтение явно производительнее записи, да и глубину я указал чрезмерную.

В том же самом примере я снижаю iodepth до 16/16 и получаю:

read 6548 iops, 2432.79usec = 2.4ms
write 5301 iops, 3005.13usec = 3ms

Очевидно, что глубина в 64 (32+32) оказалась перебором, да таким, что итоговая производительность даже упала. Глубина 32 куда более подходящий вариант для теста.

Ориентировки по производительности


Разумеется, все уже расчехляют пи… попугаемерки. Привожу значения, которые я наблюдал:
RAMDISK (rbd) — ~200kIOPS/0.1мс (iodepth=2)
SSD (intel 320ой серии) — 40k IOPS на чтение (0.8мс); около 800 IOPS на запись (после длительного времени тестирования)
SAS диск (15к RPM) — 180 IOPS, 9мс
SATA диск (7.2, WD RE) — 100 IOPS, 12мс
SATA WD Raptor — 140 IOPS, 12mc
SATA WD Green — 40 IOPS, и мне не удалось добиться latency <20 даже с iodepth=1

Предупреждение: Если вы это будете запускать на виртуальных машинах, то
а) если за IOPS'ы берут деньги — это будут весьма ощутимые деньги.
б) Если у хостера плохое хранилище, которое надеется только на кеш в несколько десятков гигабайт, то тест с большим диском (>1Тб) приведёт к… проблемам у хостера и ваших соседей по хостингу. Некоторые хостеры могут обидеться и попросить вас вон.
с) Не забывайте обнулять диск перед тестом (т.е. dd if=/dev/zero of=/dev/sdz bs=2M oflag=direct)"